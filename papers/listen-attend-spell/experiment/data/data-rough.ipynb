{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48dd90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install datasets[audio]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049098f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"mispeech/speechocean762\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07db9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3428b121",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = ds[\"train\"][:5]  # Fetches first 5 examples\n",
    "print(batch[\"text\"])\n",
    "print(batch[\"audio\"][0][\"array\"].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e371f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# Filename: prepare_speechocean_all.py\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Config\n",
    "N_MELS = 40\n",
    "WIN_MS = 25\n",
    "HOP_MS = 10\n",
    "OUTPUT_DIR = \"speechocean_all\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Setup audio transform\n",
    "spec_transform = torchaudio.transforms.MelSpectrogram(\n",
    "    sample_rate=16000,\n",
    "    n_mels=N_MELS,\n",
    "    win_length=int(16000 * WIN_MS / 1000),\n",
    "    hop_length=int(16000 * HOP_MS / 1000),\n",
    "    power=2.0\n",
    ")\n",
    "\n",
    "def waveform_to_logmel(waveform: torch.Tensor) -> torch.Tensor:\n",
    "    mel = spec_transform(waveform)\n",
    "    return torchaudio.functional.amplitude_to_DB(\n",
    "        mel, multiplier=10.0, amin=1e-5\n",
    "    )\n",
    "\n",
    "def process_and_save(split_name: str, dataset):\n",
    "    split_dir = os.path.join(OUTPUT_DIR, split_name)\n",
    "    os.makedirs(split_dir, exist_ok=True)\n",
    "\n",
    "    for ex in tqdm(dataset, desc=f\"Processing {split_name}\"):\n",
    "        utt = ex[\"utt_name\"]\n",
    "        waveform = torch.from_numpy(ex[\"audio\"][\"array\"]).unsqueeze(0)  # [1, T]\n",
    "        log_mel = waveform_to_logmel(waveform)  # [n_mels, frames]\n",
    "\n",
    "        phones_flat = [ph for w in ex[\"phones\"] for ph in w]\n",
    "        output = {\n",
    "            \"utt\": utt,\n",
    "            \"log_mel\": log_mel,           # Tensor\n",
    "            \"phonemes\": phones_flat       # List[str]\n",
    "        }\n",
    "\n",
    "        save_path = os.path.join(split_dir, f\"{utt}.pt\")\n",
    "        torch.save(output, save_path)\n",
    "\n",
    "    print(f\"Saved {len(dataset)} files to {split_dir}\")\n",
    "\n",
    "def main():\n",
    "    ds = load_dataset(\"mispeech/speechocean762\")\n",
    "    for split in [\"train\", \"test\"]:\n",
    "        process_and_save(split, ds[split])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52ab435",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# prepare_speechocean_las.py\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Configuration\n",
    "N_MELS = 40\n",
    "WIN_MS = 25\n",
    "HOP_MS = 10\n",
    "OUTPUT_DIR = \"speechocean_prepared\"\n",
    "\n",
    "# Create output directories\n",
    "for split in (\"train\", \"test\"):\n",
    "    os.makedirs(os.path.join(OUTPUT_DIR, split), exist_ok=True)\n",
    "\n",
    "# Feature extractor setup\n",
    "spec_transform = torchaudio.transforms.MelSpectrogram(\n",
    "    sample_rate=16000,\n",
    "    n_mels=N_MELS,\n",
    "    win_length=int(16000 * WIN_MS / 1000),\n",
    "    hop_length=int(16000 * HOP_MS / 1000),\n",
    "    power=2.0\n",
    ")\n",
    "\n",
    "def waveform_to_logmel(waveform: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Converts waveform tensor to log‑mel spectrogram.\"\"\"\n",
    "    mel = spec_transform(waveform)\n",
    "    return torchaudio.functional.amplitude_to_DB(mel, multiplier=10.0, amin=1e-5)\n",
    "\n",
    "def process_split(split_name: str, dataset):\n",
    "    \"\"\"\n",
    "    Processes a split of the dataset:\n",
    "    - Converts audio to log-mel features\n",
    "    - Flattens phoneme sequences\n",
    "    - Saves each sample as a .pt file\n",
    "    \"\"\"\n",
    "    out_dir = os.path.join(OUTPUT_DIR, split_name)\n",
    "    print(f\"\\nProcessing split '{split_name}' with {len(dataset)} examples\")\n",
    "\n",
    "    for ex in tqdm(dataset, desc=f\"{split_name} 💾\"):\n",
    "        utt_id = ex[\"utt_name\"]\n",
    "        # Load waveform\n",
    "        wav = torch.from_numpy(ex[\"audio\"][\"array\"]).unsqueeze(0)  # [1, T]\n",
    "        log_mel = waveform_to_logmel(wav)  # [n_mels, frames]\n",
    "\n",
    "        # Flatten list of phoneme-lists\n",
    "        phonemes = [ph for seg in ex[\"phones\"] for ph in seg]\n",
    "\n",
    "        output = {\n",
    "            \"utt\": utt_id,\n",
    "            \"log_mel\": log_mel,       # Tensor [n_mels x frames]\n",
    "            \"phonemes\": phonemes      # List[str]\n",
    "        }\n",
    "\n",
    "        torch.save(output, os.path.join(out_dir, f\"{utt_id}.pt\"))\n",
    "\n",
    "    print(f\"➡️ Saved {len(dataset)} samples to '{out_dir}'\")\n",
    "\n",
    "def main():\n",
    "    ds = load_dataset(\"mispeech/speechocean762\")\n",
    "    for split in (\"train\", \"test\"):\n",
    "        process_split(split, ds[split])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0412e0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# File: prepare_speechocean_las.py\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Config for features\n",
    "N_MELS = 40\n",
    "WIN_MS = 25\n",
    "HOP_MS = 10\n",
    "OUTPUT_DIR = \"speechocean_prepared\"\n",
    "\n",
    "# Create output directories for each split\n",
    "for split in (\"train\", \"test\"):\n",
    "    os.makedirs(os.path.join(OUTPUT_DIR, split), exist_ok=True)\n",
    "\n",
    "# Log-mel transform setup\n",
    "spec_transform = torchaudio.transforms.MelSpectrogram(\n",
    "    sample_rate=16000,\n",
    "    n_mels=N_MELS,\n",
    "    win_length=int(16000 * WIN_MS / 1000),\n",
    "    hop_length=int(16000 * HOP_MS / 1000),\n",
    "    power=2.0\n",
    ")\n",
    "\n",
    "def waveform_to_logmel(waveform: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Convert waveform [1, T] into decibel log-mel spectrogram [n_mels, time_frames].\"\"\"\n",
    "    mel = spec_transform(waveform)\n",
    "    return torchaudio.functional.amplitude_to_DB(mel, multiplier=10.0, amin=1e-5)\n",
    "\n",
    "def process_split(split_name: str, dataset):\n",
    "    \"\"\"Process and save one dataset split.\"\"\"\n",
    "    out_dir = os.path.join(OUTPUT_DIR, split_name)\n",
    "    print(f\"Processing '{split_name}' — {len(dataset)} examples\")\n",
    "\n",
    "    for ex in tqdm(dataset, desc=split_name):\n",
    "        utt = ex[\"utt_name\"]  # Utterance identifier\n",
    "        waveform = torch.from_numpy(ex[\"audio\"][\"array\"]).unsqueeze(0)  # [1, T]\n",
    "        log_mel = waveform_to_logmel(waveform)  # [n_mels, frames]\n",
    "\n",
    "        # Flatten phoneme lists (nested per word) into one list\n",
    "        phonemes = [ph for segment in ex[\"phones\"] for ph in segment]\n",
    "\n",
    "        data = {\n",
    "            \"utt\": utt,\n",
    "            \"log_mel\": log_mel,\n",
    "            \"phonemes\": phonemes\n",
    "        }\n",
    "        torch.save(data, os.path.join(out_dir, f\"{utt}.pt\"))\n",
    "\n",
    "    print(f\"✔ Saved {len(dataset)} files to '{out_dir}'\")\n",
    "\n",
    "def main():\n",
    "    ds = load_dataset(\"mispeech/speechocean762\")  # Load dataset\n",
    "    for split in (\"train\", \"test\"):\n",
    "        process_split(split, ds[split])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35dd859",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds[\"train\"].features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f89945",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# File: prepare_speechocean_las.py\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Feature configuration\n",
    "N_MELS = 40\n",
    "WIN_MS = 25\n",
    "HOP_MS = 10\n",
    "OUTPUT_DIR = \"speechocean_prepared\"\n",
    "\n",
    "# Setup output directories\n",
    "for split in (\"train\", \"test\"):\n",
    "    os.makedirs(os.path.join(OUTPUT_DIR, split), exist_ok=True)\n",
    "\n",
    "# Mel-spectrogram transformer\n",
    "spec_transform = torchaudio.transforms.MelSpectrogram(\n",
    "    sample_rate=16000,\n",
    "    n_mels=N_MELS,\n",
    "    win_length=int(16000 * WIN_MS / 1000),\n",
    "    hop_length=int(16000 * HOP_MS / 1000),\n",
    "    power=2.0\n",
    ")\n",
    "\n",
    "def waveform_to_logmel(waveform: torch.Tensor) -> torch.Tensor:\n",
    "    mel = spec_transform(waveform)\n",
    "    return torchaudio.functional.amplitude_to_DB(mel, multiplier=10.0, amin=1e-5)\n",
    "\n",
    "def process_split(split_name: str, dataset):\n",
    "    out_dir = os.path.join(OUTPUT_DIR, split_name)\n",
    "    print(f\"\\nProcessing '{split_name}' — {len(dataset)} examples\")\n",
    "\n",
    "    for i, ex in enumerate(tqdm(dataset, desc=split_name)):\n",
    "        utt_id = f\"{split_name}_{i:05d}\"\n",
    "        wav = torch.from_numpy(ex[\"audio\"][\"array\"]).unsqueeze(0)  # [1, T]\n",
    "        log_mel = waveform_to_logmel(wav)                          # [n_mels, frames]\n",
    "\n",
    "        # Flatten phoneme lists per word into one sequence\n",
    "        phonemes = [ph for w in ex[\"words\"] for ph in w[\"phones\"]]\n",
    "\n",
    "        torch.save({\n",
    "            \"utt\": utt_id,\n",
    "            \"log_mel\": log_mel,\n",
    "            \"phonemes\": phonemes\n",
    "        }, os.path.join(out_dir, f\"{utt_id}.pt\"))\n",
    "\n",
    "    print(f\"✔ Saved {len(dataset)} files to '{out_dir}'\")\n",
    "\n",
    "def main():\n",
    "    ds = load_dataset(\"mispeech/speechocean762\")\n",
    "    for split in (\"train\", \"test\"):\n",
    "        process_split(split, ds[split])\n",
    "    print(\"\\n✅ All done!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a484d908",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# File: prepare_speechocean_las.py\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Constants\n",
    "N_MELS = 40\n",
    "WIN_MS = 25\n",
    "HOP_MS = 10\n",
    "OUTPUT_DIR = \"speechocean_prepared\"\n",
    "\n",
    "# Prepare output directories\n",
    "for split in (\"train\", \"test\"):\n",
    "    os.makedirs(os.path.join(OUTPUT_DIR, split), exist_ok=True)\n",
    "\n",
    "# MelSpectrogram transform\n",
    "spec_transform = torchaudio.transforms.MelSpectrogram(\n",
    "    sample_rate=16000,\n",
    "    n_mels=N_MELS,\n",
    "    win_length=int(16000 * WIN_MS / 1000),\n",
    "    hop_length=int(16000 * HOP_MS / 1000),\n",
    "    power=2.0\n",
    ")\n",
    "\n",
    "def waveform_to_logmel(waveform: torch.Tensor) -> torch.Tensor:\n",
    "    mel = spec_transform(waveform)\n",
    "    return torchaudio.functional.amplitude_to_DB(\n",
    "        mel, multiplier=10.0, amin=1e-5\n",
    "    )\n",
    "\n",
    "def process_split(split_name: str, dataset):\n",
    "    out_dir = os.path.join(OUTPUT_DIR, split_name)\n",
    "    print(f\"\\nProcessing '{split_name}' — {len(dataset)} examples\")\n",
    "\n",
    "    for i, ex in enumerate(tqdm(dataset, desc=split_name)):\n",
    "        utt_id = f\"{split_name}_{i:05d}\"\n",
    "        # Cast waveform to float to prevent dtype mismatch errors :contentReference[oaicite:0]{index=0}\n",
    "        wav = torch.from_numpy(ex[\"audio\"][\"array\"]).unsqueeze(0).float()\n",
    "        log_mel = waveform_to_logmel(wav)\n",
    "\n",
    "        # Flatten phoneme lists per word\n",
    "        phonemes = [ph for w in ex[\"words\"] for ph in w[\"phones\"]]\n",
    "\n",
    "        torch.save({\n",
    "            \"utt\": utt_id,\n",
    "            \"log_mel\": log_mel,\n",
    "            \"phonemes\": phonemes\n",
    "        }, os.path.join(out_dir, f\"{utt_id}.pt\"))\n",
    "\n",
    "    print(f\"✔ Saved {len(dataset)} files to '{out_dir}'\")\n",
    "\n",
    "def main():\n",
    "    ds = load_dataset(\"mispeech/speechocean762\")\n",
    "    for split in (\"train\", \"test\"):\n",
    "        process_split(split, ds[split])\n",
    "    print(\"\\n✅ All done!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbde4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# File: prepare_speechocean_las.py\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "from torchaudio import transforms\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "\n",
    "# 1. Configuration\n",
    "N_MELS     = 40\n",
    "WIN_MS     = 25\n",
    "HOP_MS     = 10\n",
    "OUTPUT_DIR = \"speechocean_prepared\"\n",
    "\n",
    "# 2. Create output folders\n",
    "for split in (\"train\", \"test\"):\n",
    "    os.makedirs(os.path.join(OUTPUT_DIR, split), exist_ok=True)\n",
    "\n",
    "# 3. Define transforms\n",
    "spec_transform = transforms.MelSpectrogram(\n",
    "    sample_rate=16000,\n",
    "    n_mels=N_MELS,\n",
    "    win_length=int(16000 * WIN_MS / 1000),\n",
    "    hop_length=int(16000 * HOP_MS / 1000),\n",
    "    power=2.0\n",
    ")\n",
    "db_transform = transforms.AmplitudeToDB(stype=\"power\", top_db=80.0)\n",
    "\n",
    "def waveform_to_logmel(waveform: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    waveform: Tensor [1, T], dtype float32\n",
    "    returns : Tensor [n_mels, time_frames], dtype float32\n",
    "    \"\"\"\n",
    "    mel = spec_transform(waveform)\n",
    "    return db_transform(mel)\n",
    "\n",
    "def process_split(split_name: str, dataset):\n",
    "    out_dir = os.path.join(OUTPUT_DIR, split_name)\n",
    "    print(f\"\\n▶️  Processing split '{split_name}' with {len(dataset)} examples\")\n",
    "    for idx, ex in enumerate(tqdm(dataset, desc=split_name)):\n",
    "        # 4. Build a unique utterance ID\n",
    "        utt_id = f\"{split_name}_{idx:05d}\"\n",
    "\n",
    "        # 5. Load and cast waveform\n",
    "        wav = torch.from_numpy(ex[\"audio\"][\"array\"]).unsqueeze(0).float()  # [1, T]\n",
    "        log_mel = waveform_to_logmel(wav)                                 # [n_mels, frames]\n",
    "\n",
    "        # 6. Flatten phoneme lists\n",
    "        phonemes = []\n",
    "        for word in ex[\"words\"]:\n",
    "            phonemes.extend(word[\"phones\"])\n",
    "\n",
    "        # 7. Save to .pt\n",
    "        torch.save(\n",
    "            {\"utt\": utt_id, \"log_mel\": log_mel, \"phonemes\": phonemes},\n",
    "            os.path.join(out_dir, f\"{utt_id}.pt\")\n",
    "        )\n",
    "    print(f\"✔️  Saved {len(dataset)} tensors to '{out_dir}'\")\n",
    "\n",
    "def main():\n",
    "    # 8. Load dataset\n",
    "    ds = load_dataset(\"mispeech/speechocean762\")\n",
    "    for split in (\"train\", \"test\"):\n",
    "        process_split(split, ds[split])\n",
    "    print(\"\\n🎉 All splits processed. Data is under 'speechocean_prepared/'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f61f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "OUTPUT_FILE = \"speechocean_raw.pkl\"\n",
    "\n",
    "# Load dataset\n",
    "ds = load_dataset(\"mispeech/speechocean762\")\n",
    "\n",
    "rows = []\n",
    "for split in (\"train\", \"test\"):\n",
    "    for idx, ex in enumerate(tqdm(ds[split], desc=f\"Processing {split}\")):\n",
    "        utt_id = f\"{split}_{idx:05d}\"\n",
    "        # Store raw waveform as list of floats\n",
    "        waveform = ex[\"audio\"][\"array\"].tolist()\n",
    "        phonemes = [ph for w in ex[\"words\"] for ph in w[\"phones\"]]\n",
    "        rows.append({\n",
    "            \"split\": split,\n",
    "            \"utt\": utt_id,\n",
    "            \"waveform\": waveform,\n",
    "            \"sampling_rate\": ex[\"audio\"][\"sampling_rate\"],\n",
    "            \"phonemes\": phonemes\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_pickle(OUTPUT_FILE)\n",
    "print(f\"Saved raw data to {OUTPUT_FILE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a786934a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_pickle(\"speechocean_raw.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c80f38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00a028f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((df['phonemes'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd241b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torchaudio\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "OUTPUT_FILE = \"speechocean_logmel.pkl\"\n",
    "\n",
    "# Parameters for log-mel filterbank\n",
    "SAMPLE_RATE = 16000\n",
    "N_MELS = 40\n",
    "HOP_LENGTH = int(0.010 * SAMPLE_RATE)\n",
    "WIN_LENGTH = int(0.025 * SAMPLE_RATE)\n",
    "N_FFT = 512\n",
    "\n",
    "mel_transform = torchaudio.transforms.MelSpectrogram(\n",
    "    sample_rate=SAMPLE_RATE,\n",
    "    n_fft=N_FFT,\n",
    "    win_length=WIN_LENGTH,\n",
    "    hop_length=HOP_LENGTH,\n",
    "    n_mels=N_MELS\n",
    ")\n",
    "to_db = torchaudio.transforms.AmplitudeToDB(stype=\"power\")\n",
    "\n",
    "ds = load_dataset(\"mispeech/speechocean762\")\n",
    "\n",
    "rows = []\n",
    "for split in (\"train\", \"test\"):\n",
    "    for idx, ex in enumerate(tqdm(ds[split], desc=f\"Processing {split}\")):\n",
    "        utt_id = f\"{split}_{idx:05d}\"\n",
    "        waveform = torch.tensor(ex[\"audio\"][\"array\"], dtype=torch.float32)\n",
    "        sr = ex[\"audio\"][\"sampling_rate\"]\n",
    "\n",
    "        if sr != SAMPLE_RATE:\n",
    "            resampler = torchaudio.transforms.Resample(sr, SAMPLE_RATE)\n",
    "            waveform = resampler(waveform)\n",
    "\n",
    "        if waveform.ndim == 1:\n",
    "            waveform = waveform.unsqueeze(0)\n",
    "\n",
    "        mel_spec = mel_transform(waveform)\n",
    "        log_mel_spec = to_db(mel_spec).squeeze(0).transpose(0, 1)  # Shape: (Time, 40)\n",
    "\n",
    "        phonemes = [ph for w in ex[\"words\"] for ph in w[\"phones\"]]\n",
    "\n",
    "        rows.append({\n",
    "            \"split\": split,\n",
    "            \"utt_id\": utt_id,\n",
    "            \"log_mel\": log_mel_spec.numpy(),  # Store as NumPy array\n",
    "            \"phonemes\": phonemes\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_pickle(OUTPUT_FILE)\n",
    "print(f\"✅ Saved log-mel features to: {OUTPUT_FILE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58e3714",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_pickle(\"speechocean_logmel.pkl\")\n",
    "\n",
    "print(df)\n",
    "# Example: Access log-mel of first utterance\n",
    "log_mel = df.iloc[0][\"log_mel\"]\n",
    "phe = df.iloc[0][\"phonemes\"]\n",
    "print(\"Shape:\", log_mel.shape)  # e.g., (Time, 40)\n",
    "print(\"Phonemes:\", df.iloc[0][\"phonemes\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e718b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Use current working directory as base (not __file__)\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "# Then try import\n",
    "from utils.utils import encode, decode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbf9ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = encode(phe)\n",
    "print(\"Encoded phonemes:\", encoded)\n",
    "decoded = decode(encoded)   \n",
    "print(\"Decoded phonemes:\", decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36aee4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max(len(p) for p in df[\"phonemes\"])\n",
    "print(\"Maximum phoneme sequence length:\", max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9918ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
